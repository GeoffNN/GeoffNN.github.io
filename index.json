[{"authors":["geoff"],"categories":null,"content":"I\u0026rsquo;m a PhD student in UC Berkeley’s BAIR, advised by Prof. El Ghaoui. My research focuses on designing efficient optimization algorithms, modeling in the presence of uncertainty, and natural language processing. I\u0026rsquo;m a member of the French Armament Corps (DGA, i.e. French DARPA Fellowship). I enjoy applying my research to industry problems: I\u0026rsquo;ve interned at Bloomberg LP, Shift Technology, and am currently working part-time at SumUp Analytics. Please reach out if you are looking for optimization and NLP expertise.\n","date":1587499094,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1587597008,"objectID":"48e7158084f6027dde9dcb00a2a5feff","permalink":"https://GeoffNN.github.io/authors/geoff/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/geoff/","section":"authors","summary":"I\u0026rsquo;m a PhD student in UC Berkeley’s BAIR, advised by Prof. El Ghaoui. My research focuses on designing efficient optimization algorithms, modeling in the presence of uncertainty, and natural language processing.","tags":null,"title":"Geoffrey Négiar","type":"authors"},{"authors":["Geoffrey Négiar"],"categories":["Machine learning"],"content":"The Frank-Wolfe (FW) or Conditional Gradient algorithm is a family of first-order algorithms for constrained optimization. They seek to solve problems of the form:\n$$\\min_{x\\in \\mathcal{C}} f(x), $$\nwhere $\\mathcal{C}$ is a non-empty convex and compact set, and the objective function $f$ is differentiable, and often smooth. The gist is the following:\n Given a current iterate $x_t$, Minimize the linear approximation (i.e. the $1^\\text{st}$ order Taylor expansion) of $f$ over $\\mathcal C$ ; this minimum is attained on $s_t$, an extremal point of $\\mathcal C$; Update the iterate as a convex combination: $x_{t+1} = x_t + \\gamma_t (s_t - x_t)$ for a given step-size $\\gamma_t$.  It has many variants with different advantages, which can often be combined. My work has focused on two specific problems:\n Designing an (almost) hyper-parameter free adaptive step-size scheme, i.e. choosing $\\gamma_t$. Designing a batch-wise stochastic variant of the algorithm, reducing overall complexity of the algorithm.  ","date":1587499094,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587499094,"objectID":"600a0cfbb7c98f5382da54e89e26ec2c","permalink":"https://GeoffNN.github.io/project/frank-wolfe/","publishdate":"2020-04-21T21:58:14+02:00","relpermalink":"/project/frank-wolfe/","section":"project","summary":"Making Frank-Wolfe algorithms practical and scalable.","tags":["Optimization"],"title":"Frank-Wolfe","type":"project"},{"authors":["Geoffrey Négiar","Gideon Dresdner","Alicia Tsai","Laurent El Ghaoui","Francesco Locatello","Fabian Pedregosa"],"categories":null,"content":"","date":1580515200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1580515200,"objectID":"b6fa1c53b36def40573b29a2314a38d1","permalink":"https://GeoffNN.github.io/publication/negiar-stochastic-2020/","publishdate":"2020-04-14T03:12:12.973104Z","relpermalink":"/publication/negiar-stochastic-2020/","section":"publication","summary":"We propose a novel Stochastic Frank-Wolfe (a.k.a. Conditional Gradient) algorithm with a fixed batch size tailored to the constrained optimization of a finite sum of smooth objectives. The design of our method hinges on a primal-dual interpretation of the Frank-Wolfe algorithm. Recent work to design stochastic variants of the Frank-Wolfe algorithm falls into two categories: algorithms with increasing batch size, and algorithms with a given, constant, batch size. The former have faster convergence rates but are impractical; the latter are practical but slower. The proposed method combines the advantages of both: it converges for unit batch size, and has faster theoretical worst-case rates than previous unit batch size algorithms. Our experiments also show faster empirical convergence than previous unit batch size methods for several tasks. Finally, we construct a stochastic estimator of the Frank-Wolfe gap. It allows us to bound the true Frank-Wolfe gap, which in the convex setting bounds the primal-dual gap in the convex case while in general is a measure of stationarity. Our gap estimator can therefore be used as a practical stopping criterion in all cases.","tags":["Frank-Wolfe","Optimization","Machine Learning"],"title":"Stochastic Frank-Wolfe for Constrained Finite-Sum Minimization","type":"publication"},{"authors":["Geoffrey Négiar","Armin Askari","Fabian Pedregosa","Martin Jaggi"],"categories":null,"content":"","date":1576359900,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1576359900,"objectID":"a35b556d709ff64adb6a40e39be36b05","permalink":"https://GeoffNN.github.io/talk/optml2019/","publishdate":"2019-12-14T14:45:00-07:00","relpermalink":"/talk/optml2019/","section":"talk","summary":"Structured constraints in Machine Learning have recently brought the Frank-Wolfe (FW) family of algorithms back in the spotlight. Recently, the Away-steps (A) and Pairwise (P) FW variants have been shown to converge linearly for polytopic constraints. However, these improved variants suffer from two practical limitations: each iteration requires solving a 1-dimensional minimization problem to determine the step-size along with an exact solution to the Frank-Wolfe linear subproblems. In this paper, we propose simple modifications of AFW and PFW that lift both restrictions simultaneously. Our method relies on a sufficient decrease condition to determine the step-size. It only requires evaluation and gradient oracles on the objective, along with an approximate solution to the FrankWolfe linear subproblems. Furthermore, the theoretical convergence rates of our methods match ones for the exact line-search versions. Benchmarks on different machine learning problems illustrate large practical performance gains of the proposed variants.","tags":["Frank-Wolfe","Optimization"],"title":"Linearly Convergent Frank-Wolfe without Prior Knowledge","type":"talk"},{"authors":["Fabian Pedregosa","Geoffrey Négiar","Armin Askari","Martin Jaggi"],"categories":null,"content":"","date":1528848000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1528848000,"objectID":"f0ff6d3b08e071c169a04e61b7ff9e68","permalink":"https://GeoffNN.github.io/publication/pedregosa-linearly-2020/","publishdate":"2020-01-14T03:12:12.973981Z","relpermalink":"/publication/pedregosa-linearly-2020/","section":"publication","summary":"Structured constraints in Machine Learning have recently brought the Frank-Wolfe (FW) family of algorithms back in the spotlight. While the classical FW algorithm has poor local convergence properties, the Away-steps and Pairwise FW variants have emerged as improved variants with faster convergence. However, these improved variants suffer from two practical limitations: they require at each iteration to solve a 1-dimensional minimization problem to set the step-size and also require the Frank-Wolfe linear subproblems to be solved exactly. In this paper, we propose variants of Away-steps and Pairwise FW that lift both restrictions simultaneously. The proposed methods set the step-size based on a sufficient decrease condition, and do not require prior knowledge of the objective. Furthermore, they inherit all the favorable convergence properties of the exact line-search version, including linear convergence for strongly convex functions over polytopes. Benchmarks on different machine learning problems illustrate large performance gains of the proposed variants.","tags":["Frank-Wolfe","Optimization"],"title":"Linearly Convergent Frank-Wolfe with Backtracking Line-Search","type":"publication"},{"authors":["Armin Askari","Geoffrey Negiar","Rajiv Sambharya","Laurent El Ghaoui"],"categories":null,"content":"","date":1527811200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1527811200,"objectID":"906d737c02a287fa214b36022b56aa8e","permalink":"https://GeoffNN.github.io/publication/askari-lifted-2018/","publishdate":"2020-04-14T03:12:12.973598Z","relpermalink":"/publication/askari-lifted-2018/","section":"publication","summary":"We describe a novel family of models of multi-layer feedforward neural networks in which the activation functions are encoded via penalties in the training problem. Our approach is based on representing a non-decreasing activation function as the argmin of an appropriate convex optimization problem. The new framework allows for algorithms such as block-coordinate descent methods to be applied, in which each step is composed of a simple (no hidden layer) supervised learning problem that is parallelizable across data points and/or layers. Experiments indicate that the pro- posed models provide excellent initial guesses for weights for standard neural networks. In addition, the model provides avenues for interesting extensions, such as robustness against noisy inputs and optimizing over parameters in activation functions.","tags":["Computer Science - Machine Learning","Statistics - Machine Learning"],"title":"Lifted Neural Networks","type":"publication"},{"authors":["Geoffrey Négiar"],"categories":["tutorial"],"content":"Hi everyone, welcome back. Tonight I was having dinner with some engineer friends (sadly not a plat en sauce) and the subject of Machine Learning popped up.\nThe discussion quickly almost turned religious, between believers and non believers, those that thought it\u0026rsquo;s over hyped, those who just use it as a tool and those who research it like myself. All in all, it made me feel that even engineers have a very vague sense of what exactly is Machine Learning. I\u0026rsquo;ve noticed people in general often mix it up with other concepts that either include it such as AI or that it includes such as the Supervised Learning paradigm. Since it\u0026rsquo;s been a long time that I\u0026rsquo;ve been wanting to address this issue, here I go.\nThe aim of this article is to explain ML assuming that you already have some general mathematical background, and have (very) basic knowledge of optimization i.e. you know what argmin is. I also assume that you can read equations. My definition of Machine Learning is the following:\n Choosing a task and learning a statistical model from data that will perform well on this task.\n This definition seems extremely vague, so I\u0026rsquo;ll explain each part in more detail. I\u0026rsquo;m intentionally leaving out complications due to taking into account randomness in the data. Of course we need this both in theory and in practice.\nChoosing a task Examples of tasks are recognizing handwritten digits, translating sentences from a language to another, identifying people in pictures, forecasting the weather or stock prices, grasping an object with a robot arm\u0026hellip; Basically any clear-cut problem is a task. This part doesn\u0026rsquo;t suppose an actual mathematical expression of the task. On the other hand, it does require to be very precise as we\u0026rsquo;ll see in the following example.\nA model that will perform well To define what perform well means, you often want to define a loss or cost function for your task, that given your data and model, i.e. the specific function of your data you\u0026rsquo;re considering, outputs a measure of its performance. A simple example: suppose my (very basic) task is to always output the number 0. A good metric could be the distance of my function output to 0. Then it\u0026rsquo;s obvious that if f and g are the constant functions respectively equal to 42 and 0.2, g performs better on this task than f, for every distance function other than the 0-1 distance. All these different distance functions yield a different metric for the same task. The problem is then to minimize your loss function over the class of functions that you will choose in the next step.\nA statistical model Choosing a class of functions that take as inputs the data you want to use for the task, i.e. often a high-dimensional vector, and outputs a real number or another vector. A class of functions is a group of functions that share a certain structure, with different parameters. An example of this is the class of linear functions that can be written : $f(X) = Xw + b $, where vectors $w$ and scalar $b$ are the parameters.\nLearning the model This here is the actual way that you will choose your function that minimizes your loss over your data in the class of functions that you chose. This is the learning and what makes ML so compelling to me, and makes it treated as almost magical in the media. It is usually done by optimizing the loss function, either in a principled or heuristic way. Optimization is the field of studying how to find minima of loss functions (sometimes under constraints).\nThis is also what made the success of deep learning, where in the parameter space, the overall loss is differentiable with regard to the parameters, allowing us to simply glide towards a (near) optimal solution using Stochastic Gradient Descent.\nWho does what? ML to me is described by these 4 steps. Both researchers and engineers usually focus on a subset of these steps. For example, for a well-known task such as classification (i.e. for each data point, outputting the category it should belong to), or regression (for each data point, predicting the value of something), both the task and the loss function are well known. Most work can then focus on choosing the model family and how to compute the best model of the family. On the other hand, for unsupervised learning tasks, the task is not as clear, and the loss is an open question. On their side, ML engineers will often have a hard time modelling their domain-specific task in a nice loss function, and then apply known model families and optimization schemes.\nNow for an example Let\u0026rsquo;s consider the task (step 1) of recognizing hand written digits, supposing that we know the ground truth for a subset of our data \u0026ndash; we\u0026rsquo;ll call this subset our training set. Our input is going to be a 784 (ie. 28x28)-vector representing an image. Each of its dimensions corresponds to a pixel in the image. Here is a sample image for a 1:\n  Sample image and matrix representation. From old Tensorflow tutorials. Dimensions are incorrect.   Now that we identified our task, we want to model it using a loss function (step 2). We want our output to tell us if the sample is a 0, 1, 2\u0026hellip; or 9. An intuitive way to represent this is to have a 0-1 error function : if we predict the correct label, our loss is 0 and 1 if we make a mistake. Machine Learners rarely use this in practice because the discrete nature of this loss make the 4th step, the learning, harder.\nA common and smart way to represent a very similar task is to have our function output a vector of probabilities over the 10 classes, i.e. a positive vector of size 10, with coordinates that sum to 1. Our new proxy task is predicting how likely a sample is to belong to a certain class, given labelled training data. We\u0026rsquo;ll call this vector $ \\hat{y}$ as opposed to $ y$ which is the correct probability distribution, where $ y_i = 1$ if and only if $ i$ is the correct class of our data point. We need a metric to tell if $ \\hat{y}$ is far from $ y$. Cross entropy is the go-to method for this. Its expression for each data sample is:\n$$ L(\\hat{y}, y) = -\\sum_i y_i \\log(\\hat{y_i})$$\nNote that if we did not know the $y_i$, it would be a different task, and would thus require a different loss function.\nIn practice, we\u0026rsquo;ll minimize the empirical average of this loss over our training data.\nAt this point, we want to find our model class, i.e. the structure in our functions $f$. An easy example is using a one-hidden-layer neural network, with a sigmoid activation function $\\sigma$. $f$ can be written as:\n$$ f(x) = \\sigma ( X W_0+ b_0)w_1 + b_1$$\nSo our model is the set of functions that can be written this way, for any weights $W_0, w_1, b_0, b_1$.\nFinally comes the learning. We want to learn what function of our class minimizes our loss. This is equivalent to finding the weights that minimize our loss, given the preceding structure. Mathematically, our minimization problem is:\n$$\\min_{W_0, w_1, b_0, b_1} - \\sum_{i,j} y_i \\log(\\sigma (X_jW_0 + b_0)w_1 + b_1)$$\nwhere the sum over $i$ refers to the different classes $(0, 1,\u0026hellip;9)$ in our problem and the sum over $j$ refers to the different samples in our training set.\nNB for you who are familiar with optimization: This problem is somewhat nice, because the loss function is differentiable with respect to the weights, although it is not convex in the weights. This explains why people use Stochastic Gradient Descent, an algorithm that guarantees us to find a local minimum of our loss and the corresponding weights.\nOnce we find the optimal weights, we have our candidate, and have finished our learning! For this particular digit recognition dataset, common classification error runs around 5% on a validation set. The classification error used here is the intuitive 0-1 loss that we defined earlier.\nA validation set is a set similar to the training set, meaning that we also know the correct labels $y_i$. The difference with the training set is that we never fed it to the learning algorithm. This means our model\u0026rsquo;s parameters were not optimized for outputting correct results for the validation set. The hope is that the parameters we learned generalize enough to work well on the validation set. We want this so that we are confident our model will perform well on any new data we feed to it, assuming this data was generated in the same manner as the training data. More on this in a future post.\nConclusion I went over what makes a problem a Machine Learning problem: the 4 phases of Choosing a Task, Modelling the Task, Choosing a Model Class, and Learning i.e. Optimizing over the Model Class. I hope the example helped to clear this up. We also saw that by trying to solve a specific task, we may have to define a new task that is a good proxy for our original task. In the end though, we always validate our approach on the first task on held-out data, using the loss function that we designed for it, here the 0-1 error loss.\nI hope this helps making Machine Learning less of a buzz word and more understandable! I\u0026rsquo;m looking forward to your comments, don\u0026rsquo;t hesitate to leave one below.\nGoing further The Bible of ML: Hastie, T.; Tibshirani, R. \u0026amp; Friedman, J. (2001), The Elements of Statistical Learning , Springer New York Inc. , New York, NY, USA .\nThe Bible of Optimization, basic and advanced: Boyd, S.; and Vandenberghe, L. (2004), Convex Optimization. Cambridge University Press, New York, NY, USA.\nThe Bible of Deep Learning: Goodfellow, I.; Bengio Y.; and Courville, A. (2016), Deep Learning. MIT Press\n","date":1509582871,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587499711,"objectID":"e25fd3fa52779335359d1085e9a003d3","permalink":"https://GeoffNN.github.io/post/what-is-machine-learning/","publishdate":"2017-11-02T02:34:31+02:00","relpermalink":"/post/what-is-machine-learning/","section":"post","summary":"In this post, I look at the different parts of a typical machine learning problem.","tags":["machine learning","tutorial"],"title":"What Is Machine Learning","type":"post"},{"authors":["Geoffrey Négiar"],"categories":["food"],"content":"Hi all! Here is my first post on food! I hope you enjoy it and am looking forward to your comments! Today, I\u0026rsquo;ll focus on the French Plat en sauce concept.\nI found an old cooking book in one of my parents\u0026rsquo; shelves a few months ago and finally got around to checking it out and trying some things in it. The book is called Le Répertoire de la Cuisine (1914 for the first edition) by Théodore Gringoire and Louis Saulnier. The Répertoire is a major guide/recipe book for people who already know some technical French cuisine vocabulary - but nowadays, you can just Google them and find out all about what monder, singer or chemiser mean. I won\u0026rsquo;t reproduce the recipe from the book here - you can probably find a PDF on internet or buy it on Amazon. I will add my own recipes in the following days, tune back in soon!\nI moved to the US a few months ago, and started missing the homey family French cuisine tastes. In my mind, nothing is more characteristic of this than a Blanquette and other plats en sauce : sauce entrées where meat and veggies are slowly cooked with herbs and wine. I read and tried a few different recipes from the Répertoire inspired from Estouffade (traditionnelle and à la provençale) and Blanquette. My maths/CS background made me realize that these can all be abstracted to a generic Plat en sauce, which most of you experienced cooks probably already know. Couscous, Coq au vin, Bœuf bourguignon, Fricassée or even Curry implement this. They\u0026rsquo;re all pretty cheap and healthy dishes, and the abstraction allows for creation and variation depending on your current tastes and desires. Here is what makes up a good plat en sauce in my mind, with the usual French interpretations of each category.\n Meat: beef stew or equivalent for other animals such as veal or lamb. Fonds: stock - traditionally either white if made from poultry, veal or vegetables or brown if made from red meat Wine: same color as the fonds, i.e. red for dark fonds and white for light fonds. Vegetables: usually onions, carrots and mushrooms at least - any other root can do, e.g. parsnip for some tartness Carbs: usually rice or steamed potatoes, the former being my favorite to have a donburi-style Plat en sauce where the rice gets soaked in the sauce. Spices, herbs and various seasonings: bouquet garni (thyme, rosemary and sage) is the most frequent for French dishes, but Ras El-Hanout would be its couscous equivalent. I also consider the egg/heavy cream in Blanquette in this category. Optional: a roux to make the sauce thicker. Always add this at the very end.   Onions have two uses in these recipes: sliced onions, usually in quarters, are for eating, and whole onions are spiked with cloves to flavor the broth and to facilitate removing the cloves in one go before serving the dish. This allows not to end up with a violent clove surprise while eating.\n Roux: mix melted butter and flour (around half and half) and cook till the mixture is the color you want. Darker gives a more nutty taste, but doesn\u0026rsquo;t thicken the sauce as much. Always mix with a few ladles of sauce first before pouring in the main pot to avoid lumps.\nI\u0026rsquo;ll progressively add my recipes for different implementations of Plat en sauce as soon as I\u0026rsquo;ve tweaked them well enough, come back soon for more! Check my Recipes page for the up to date version.\nLet me know if this helped you make one of these dishes or if you tried deriving a new plat en sauce from the abstraction! Here are some ideas that I\u0026rsquo;d like to try:\n a vegetarian one, using tofu and vegetable stock using ichiban-dashi (kombu seaweed and fish stock) for an umami-tasting base  ","date":1496099408,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587597008,"objectID":"df27ece036a917b4d2bdd4d63f5361ed","permalink":"https://GeoffNN.github.io/post/plat-en-sauce-abstraction/","publishdate":"2017-05-30T01:10:08+02:00","relpermalink":"/post/plat-en-sauce-abstraction/","section":"post","summary":"Hi all! Here is my first post on food! I hope you enjoy it and am looking forward to your comments! Today, I\u0026rsquo;ll focus on the French Plat en sauce concept.","tags":["food","plat en sauce"],"title":"Plat en Sauce Abstraction","type":"post"}]